# Graph ML/GNN Reading Group 


## Meeting Time and Location 
Tuesdays 4:30- 6pm at Stanford Gates 415 ([google calendar](https://calendar.google.com/event?action=TEMPLATE&tmeid=M3IzbzBtMHZ2MDFnbGVoM3NiZGVqZDNtZ2tfMjAyMjA2MjhUMjMzMDAwWiBxaWFuMTIzcXdAbQ&tmsrc=qian123qw%40gmail.com&scp=ALL)[zoom](https://stanford.zoom.us/j/99662423809?pwd=N1VTZnVNeGM0MU0veWhQckQ1YUJsUT09))


## Introductory Material

- [Jure’s CS 224w](https://web.stanford.edu/class/cs224w/index.html#schedule) (Lecture 6 onwards)
- [Graph Representation Learning](https://www.cs.mcgill.ca/~wlh/grl_book/), book by Will Hamilton
- GNN Intro Blog Posts
  - <https://distill.pub/2021/gnn-intro/>
  - <https://distill.pub/2021/understanding-gnns/>
- [Moses’s repository of survey papers](https://www.dropbox.com/sh/61cpaowg8ityuin/AAAlpRRkbbRp7sy0-0hq9XMWa?dl=0)

## Schedule 

### Summer 2022

- 6/28/2022: Invariant Neural Nets for Eigenvectors, and other Invariances / Equivariances in Graph Machine Learning
  - Presenter: Derek Lim, Joshua Robinson
  - Related papers: [Sign and Basis Invariant Networks for Spectral Graph Representation Learning](https://arxiv.org/abs/2202.13013)
  - Abstract: Various invariances and equivariances have been found to be useful for graph machine learning. Recently, invariance to symmetries exhibited by Laplacian eigenvectors has been shown to be beneficial for processing graphs.  We introduce SignNet and BasisNet -- the first neural architectures that are invariant to two key symmetries displayed by eigenvectors: (i) sign flips, since if v is an eigenvector then so is −v; and (ii) more general basis symmetries, which occur in higher dimensional eigenspaces with infinitely many choices of basis eigenvectors. We prove that our networks are universal, i.e., they can approximate any continuous function of eigenvectors with the desired invariances. Moreover, when used with Laplacian eigenvectors, our architectures are provably expressive for graph representation learning: they can provably compute useful functions on graphs that many other models cannot.

- 7/5/2022: Break

- 7/12/2022: CLRS benchmark and Graph Neural Networks are Dynamic Programmers (at 11am)
  - Presenter: Petar Veličković
  - Related papers: 
    - [The CLRS Algorithmic Reasoning Benchmark](https://arxiv.org/abs/2205.15659)
    - [Graph Neural Networks are Dynamic Programmers](https://arxiv.org/abs/2203.15544)


### Spring 2022 

- 4/5/2022: Tutorial on GNN and expressive power
  - Presenter: Weihua Hu
  - [Slides](https://drive.google.com/file/d/1UtYBc-8e85Id9PAoahzXEgjuv9Zr11QJ/view?usp=sharing)
  - Related papers:
    - [How Powerful are Graph Neural Networks?](https://arxiv.org/abs/1810.00826)

- 4/12/2022: Discussion on expressive power of GNN
  - Presenter: Qian Huang
  - [Slides](https://docs.google.com/presentation/d/1A19TdVsAh6KwwokOObkovVUFW4Cykyb7P4cm0Taj8Lk/edit?usp=sharing)
  - Related papers:
    - [How Powerful are Graph Neural Networks?](https://arxiv.org/abs/1810.00826) (last week Weihua’s presentation)
    - [What Can Neural Networks Reason About](https://arxiv.org/abs/1905.13211)
    - [Graph Neural Networks are Dynamic Programmers](https://arxiv.org/abs/2203.15544)
    - [The Exact Class of Graph Functions Generated by Graph Neural Networks](https://arxiv.org/abs/2202.08833)
 
- 4/19/2022: Discussion on expressive power of GNN and open problem
  - Presenter: Amin Saberi
 
- 4/26/2022: Discussion on expressive power of GNN and open problem
  - Presenter: Yeganeh Alimohammadi
  - Related papers:
    - [Generalization and Representational Limits of Graph Neural Networks](https://arxiv.org/abs/2002.06157) 
    - [Topological Graph Neural Networks](https://arxiv.org/pdf/2102.07835.pdf)

- 5/3/2022: Constraint satisfaction and Combinatorial problems
  - Presenter: Aidan Perreault, Moses Charikar
  - Related papers:
    - [Graph Neural Networks for Maximum Constraint Satisfaction](https://arxiv.org/abs/1909.08387)
    - [Learning a SAT Solver from Single-Bit Supervision](https://arxiv.org/abs/1802.03685) 
    - [Combinatorial optimization and reasoning with graph neural networks](https://arxiv.org/abs/2102.09544)
 
- 5/11/2022: Auto-scaling GNNs & PyG 2.0
  - Presenter: [Matthias Fey](https://rusty1s.github.io/#/)
  - [Slides](https://drive.google.com/file/d/1J5Zxd1LhDKVX0VtMU1y21GZ-48FI8Z9i/view?usp=sharing)

- 5/24/2022: GNN Embedding
  - Presenter: [Rex Ying](https://cs.stanford.edu/people/rexy/)
  - [Slides](https://drive.google.com/file/d/1VXlSsJu9kbUQVz16Vi4baidpv-S5nfxT/view?usp=sharing)

- 5/31/2022: Hyperbolic GNN Embedding
  - Presenter: Aaron Lou
  - [Slides](https://drive.google.com/file/d/1HRvlyB8EHzU3hQdvX3sNzbl4apygAP3Z/view?usp=sharing)

- 6/7/2022: Box Embedding for KG reasoning
  - Presenter: Hongyu Ren
  - [Slides](https://drive.google.com/file/d/1liAX6Mekp0a5HthivsyS5dfFLZxb8mRm/view?usp=sharing)

## Other Topics and Papers for Future

- Graph generative models: Amin, Yeganeh, Jared, Moses
  - [Evaluation Metrics for Graph Generative Models: Problems, Pitfalls, and Practical Solutions (ICLR 22)](https://arxiv.org/pdf/2106.01098.pdf)
  - [On Evaluation Metrics for Graph Generative Models (ICLR 22)](https://arxiv.org/pdf/2201.09871.pdf)

-  GNN Oversquashing
  - [On the Bottleneck of Graph Neural Networks and its Practical Implications](https://arxiv.org/abs/2006.05205)
  - [Understanding over-squashing and bottlenecks on graphs via curvature (ICLR 22)](https://arxiv.org/pdf/2111.14522.pdf)

- GNN + geometric representation learning (non-euclidean space)
 - [Hyperbolic Graph Neural Networks](https://arxiv.org/abs/1910.12892)
 - [Hyperbolic Graph Convolutional Neural Networks](https://arxiv.org/abs/1910.12933) 

- Geometric Deep Learning, Invariant/equivariant Graph Networks
  - <https://www.youtube.com/watch?v=7pRIjJ_u2_c>
  - <https://www.dropbox.com/sh/u9o69w4rm0uvmzi/AADLGwfdcY94HVsz2eSoCAFPa/invariant%20graph%20networks?dl=0&subfolder_nav_tracking=1> 
  - [E(n) Equivariant Graph Neural Networks](https://arxiv.org/abs/2102.09844)

- Simplification 
  - [Simplifying Graph Convolutional Networks](https://arxiv.org/abs/1902.07153)
  - [Combining Label Propagation and Simple Models Out-performs Graph Neural Networks](https://arxiv.org/abs/2010.13993)

- Hypergraphs
  - <https://www.dropbox.com/sh/u9o69w4rm0uvmzi/AADtWutKnbOw0NuxPRpYOwlla/hypergraphs?dl=0&subfolder_nav_tracking=1>
 
- Others 
  - [Discovering Symbolic Models from Deep Learning with Inductive Biases](https://arxiv.org/abs/2006.11287)
  - Applications on knowledge graph, drug discovery etc
 
## Organizers and Participants
 - Moses Charikar <moses@cs.stanford.edu>
 - Amin Saberi <saberi@stanford.edu>
 - Jure Leskovec <jure@cs.stanford.edu>
 - Qian Huang <qhwang@cs.stanford.edu>
 - [Participants](https://docs.google.com/document/d/17nf-aUpaMCghkWTLBmaiZW1nmOKrxwqRIsDJO_h3658/edit?pli=1#)

 
